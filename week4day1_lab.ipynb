{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentals of Social Data Science\n",
    "# Week 4 Day 1 Lab. Classification \n",
    "\n",
    "In this lab, you will be encouraged to explore your subreddits of choice using multinomial naive bayes and k-means classifications. Determine which one is more suitable using accuracy scores. Use both the TfIDFVectorizer and the CountVectorizer. \n",
    "\n",
    "Consider the use of stop words and lemmatisation. \n",
    "\n",
    "1. Plot the documents using t-SNE and then color the documents according the most accurate solution. \n",
    "2. For Naive Bayes report the 5 most informative terms per solution.  \n",
    "* Would you be able to report the 5 most informative terms with k-means? This would be a bit far out for this lecture but if you are adventurous you can explore approaches like k-nearest neighbors using the centroids (as in report the 5 nearest neighbors to the centroid for each of the k solutions). \n",
    "\n",
    "There is only limited example code for this exercise. It is up to you to stitch together what you have learned as well as potentially draw upon external sources. On Wednesday we will provide an example solution.\n",
    "\n",
    "Some guidance: \n",
    "1. Transform your headlines into a list similar to the walkthrough: [(\"headline (and maybe selftext)\", \"subreddit_label\"), (\"next headline\", \"next subreddit_label\")]\n",
    " * Create one long list for all three subreddits to send to the Vectorizer. This is different to what I showed in Week 3 Day 3 where we had a separate vectorizer for each subreddit. To help you out I've started some code that creates a DataFrame for all the subs. \n",
    "2. Consider your tokenization. Will you use stop words or not? \n",
    "3. Consider plotting the classification on t-SNE to get some intuitions for how the solution maps out visually. \n",
    "4. Remember, are you classifying the documents using the terms? Or classifying the terms using the documents? Be careful with how you set this up. Notice that in the examples in the walkthrough we were classifying the documents using the terms. \n",
    "5. Consider the structure of this repository. Will you want to place some code for a plotting function in the `analysis.py`? What about creating a function under `text_processor.py` to transform the reddit data into the data structure needed. You can do everything in this Jupyter lab notebook but you should use this opportunity to think about how you might make use of this structure in order to help keep your code tidy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from models.reddit_scraper import RedditScraper\n",
    "from config.settings import USER_AGENT\n",
    "from utils.analysis import *\n",
    "\n",
    "scraper = RedditScraper(USER_AGENT)\n",
    "subs_of_interest = ['unitedkingdom', 'ukpolitics', 'uknews']\n",
    "\n",
    "posts_list = []\n",
    "\n",
    "for sub in subs_of_interest:    \n",
    "    posts = scraper.get_subreddit_posts(sub, limit=100, cache=True)\n",
    "    df = create_posts_dataframe(posts)\n",
    "    df['subreddit'] = sub\n",
    "    posts_list.append(df)\n",
    "\n",
    "posts_df = pd.concat(posts_list)\n",
    "posts_df = posts_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise NBC results: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise k-Means results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
